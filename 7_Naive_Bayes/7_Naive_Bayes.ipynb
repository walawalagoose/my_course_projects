{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 导入相关软件包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import jieba\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机种子\n",
    "def seed_pytorch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_para = {\n",
    "    'data_path': \"C:\\\\Users\\\\Jiazhen Huang\\\\Downloads\\\\THUCNews\",\n",
    "    'seed':42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pytorch(seed=config_para['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别列表: ['体育', '娱乐', '家居', '彩票', '房产', '教育', '时尚', '时政', '星座', '游戏', '社会', '科技', '股票', '财经']\n"
     ]
    }
   ],
   "source": [
    "# 获取类别列表（这里只有教育）\n",
    "data_dir = config_para['data_path']\n",
    "\n",
    "class_list = [category for category in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, category))]\n",
    "print(\"类别列表:\", class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文本数据和对应的label\n",
    "# 数据太多了，在这里选了每个类别2000个case\n",
    "\n",
    "features, labels = [], []\n",
    "max_text_cnt = 2000\n",
    "for category in class_list:\n",
    "    category_path = os.path.join(data_dir, category)\n",
    "    text_files = [text_file for text_file in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, text_file))]\n",
    "    \n",
    "    # 如果当前类别的样本数超过 max_text_cnt，则随机选择 max_text_cnt 个样本\n",
    "    if max_text_cnt is not None and len(text_files) > max_text_cnt:\n",
    "        text_files = random.sample(text_files, max_text_cnt)\n",
    "    \n",
    "    # 加载选中的文本数据和标签\n",
    "    for text_file in text_files:\n",
    "        text_path = os.path.join(category_path, text_file)\n",
    "        with open(text_path, \"r\", encoding='utf-8') as file:\n",
    "            content = file.read().strip()\n",
    "            features.append(content)\n",
    "            labels.append(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词处理\n",
    "def process_text(X):\n",
    "    return [\"\".join(jieba.cut(text)) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词处理\n",
    "def make_words_set(words_file):\n",
    "    stopwords_list = []\n",
    "    with open(words_file, 'r', encoding='utf-8') as fp:\n",
    "        for line in fp:\n",
    "            word = line.strip()\n",
    "            if len(word) > 0 and word not in stopwords_list:\n",
    "                stopwords_list.append(word)\n",
    "    return stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行特征提取\n",
    "\n",
    "# 加载停用词\n",
    "stopwords_set = make_words_set('./stopwords_cn.txt')\n",
    "\n",
    "# 特征提取，并转换为array\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_set, max_features=3000)\n",
    "features = vectorizer.fit_transform(process_text(features)).toarray()\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 3000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayesCustom:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.voc_size = None # 词表大小\n",
    "        self.prior = {} # 先验概率\n",
    "        self.cond = defaultdict(dict) # 条件概率\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        self.voc_size = X.shape[1]\n",
    "        \n",
    "        # 计算先验概率 P(y)\n",
    "        for c in self.classes:\n",
    "            self.prior[c] = np.sum(y == c) / len(y)\n",
    "        \n",
    "        # 计算条件概率 P(x|y)\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            class_word_count = X_c.sum(axis=0)\n",
    "            total_word_count = class_word_count.sum()\n",
    "            \n",
    "            # 这里使用了拉普拉斯平滑：P(x|y) = (词x在类别y中的出现次数 + 1) / (类别y的总词数 + 词表大小)\n",
    "            self.cond[c] = (class_word_count + 1) / (total_word_count + self.voc_size)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            x = x.flatten()\n",
    "            post = {}\n",
    "            for c in self.classes:\n",
    "                log_prob = np.log(self.prior[c])\n",
    "                for i in range(self.voc_size):\n",
    "                    if x[i] > 0:\n",
    "                        log_prob += x[i] * np.log(self.cond[c][i])\n",
    "                post[c] = log_prob\n",
    "            predictions.append(max(post, key=lambda k: post[k]))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置了一个统一的评估接口，保证简便性\n",
    "def evaluate(model, X, y, n_splits=10):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=config_para['seed'])\n",
    "    metrics = {\n",
    "        \"accuracy\": [],\n",
    "        \"precision_macro\": [],\n",
    "        \"recall_macro\": [],\n",
    "        \"f1_macro\": [],\n",
    "        \"precision_micro\": [],\n",
    "        \"recall_micro\": [],\n",
    "        \"f1_micro\": []\n",
    "    }\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 这里同时计算了宏平均和微平均，因为acc本来就是全局指标，所以没有macro/micro之分\n",
    "        metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "        metrics[\"precision_macro\"].append(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "        metrics[\"recall_macro\"].append(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "        metrics[\"f1_macro\"].append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "        metrics[\"precision_micro\"].append(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "        metrics[\"recall_micro\"].append(recall_score(y_test, y_pred, average=\"micro\"))\n",
    "        metrics[\"f1_micro\"].append(f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    \n",
    "    # 计算平均值\n",
    "    for key in metrics:\n",
    "        metrics[key] = np.mean(metrics[key])\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化实验设置\n",
    "\n",
    "# 训练与评估\n",
    "model = MultinomialNaiveBayesCustom()\n",
    "\n",
    "# 评估模型\n",
    "metrics = evaluate(model, features, labels, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验结果：\n",
      "Accuracy: 0.694286\n",
      "Precision (Macro): 0.725842\n",
      "Recall (Macro): 0.694286\n",
      "F1-Value (Macro): 0.697446\n",
      "Precision (Micro): 0.694286\n",
      "Recall (Micro): 0.694286\n",
      "F1-Value (Micro): 0.694286\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "print(\"实验结果：\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.6f}\")\n",
    "print(f\"Precision (Macro): {metrics['precision_macro']:.6f}\")\n",
    "print(f\"Recall (Macro): {metrics['recall_macro']:.6f}\")\n",
    "print(f\"F1-Value (Macro): {metrics['f1_macro']:.6f}\")\n",
    "print(f\"Precision (Micro): {metrics['precision_micro']:.6f}\")\n",
    "print(f\"Recall (Micro): {metrics['recall_micro']:.6f}\")\n",
    "print(f\"F1-Value (Micro): {metrics['f1_micro']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
